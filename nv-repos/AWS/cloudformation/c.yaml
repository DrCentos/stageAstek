---
AWSTemplateFormatVersion: '2010-09-09'
Resources:
  NvBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: nv2bucket

  NvDBSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: Subnet Group for RDS Instance
      SubnetIds:
        - 'subnet-010fb6db5f6c2edd4'
        - 'subnet-01f473cfbb6f597da'

  NvRDSInstance:
    Type: AWS::RDS::DBInstance
    Properties:
      Engine: mysql
      DBName: nvrds
      AllocatedStorage: 20
      DBInstanceIdentifier: nvrds
      MasterUsername: nicolasvallot
      MasterUserPassword: nicolasvallot
      DBInstanceClass: db.t2.micro
      VPCSecurityGroups:
        - !Ref NvRDSSecurityGroup
      DBSubnetGroupName: !Ref NvDBSubnetGroup

  NvRDSSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Enable access to RDS
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 3306
          ToPort: 3306
          CidrIp: 0.0.0.0/0

  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: LambdaBasicExecution
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: arn:aws:logs:*:*:*

  NvLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.9
      Environment:
        Variables:
          BUCKET_NAME: !Ref NvBucket
          DB_HOST: !GetAtt NvRDSInstance.Endpoint.Address
          DB_USER: nicolasvallot
          DB_PASSWORD: nicolasvallot
          DB_NAME: nvrds
      Code:
        ZipFile: |
          import json
          import boto3
          import pymysql
          import os

          def handler(event, context):
              s3_client = boto3.client("s3")
              bucket_name = os.environ["BUCKET_NAME"]

              data = [
              {"CustID": 1054, "Name": "Richard Roe"},
              {"CustID": 121, "Name": "selen Roe"},
              {"CustID": 2, "Name": "Alex Valette"},
              {"CustID": 3, "Name": "Nico Vallot"}
              ]

              # Create and upload JSON file to S3 bucket
              file_name = "customers.json"
              s3_client.put_object(Bucket=bucket_name, Key=file_name, Body=json.dumps(data))

              # Connect to RDS
              connection = pymysql.connect(
                  host=os.environ["DB_HOST"],
                  user=os.environ["DB_USER"],
                  password=os.environ["DB_PASSWORD"],
                  database=os.environ["DB_NAME"],
              )

              with connection.cursor() as cursor:
                  # Create table if not exists
                  create_table_query = """
                  CREATE TABLE IF NOT EXISTS customers (
                      CustID INT PRIMARY KEY,
                      Name VARCHAR(255) NOT NULL
                  );
                  """
                  cursor.execute(create_table_query)
                  connection.commit()

                  # Insert data into the RDS table
                  for item in data:
                      insert_query = f"""
                      INSERT INTO customers (CustID, Name) VALUES ({item["CustID"]}, '{item["Name"]}')
                      ON DUPLICATE KEY UPDATE Name='{item["Name"]}';
                      """
                      cursor.execute(insert_query)
                      connection.commit()

              connection.close()
              return {"statusCode": 200, "body": json.dumps("Data uploaded to RDS.")}

