# -*- coding: utf-8 -*-
"""nvnote.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vwqTQYf-csyNdOD-W6Z3J0444r1rUgrg
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install sparkmagic
# %pip install pyspark

# Commented out IPython magic to ensure Python compatibility.
# %pip install pandas

import sys
from os import path

current_folder = path.dirname(path.abspath(__file__))
import subprocess
subprocess.check_call([sys.executable, "-m", "pip", "install", "pyspark", "boto3","pandas","sparkmagic","s3fs","fsspec", "-t", current_folder])


import pandas as pd
import boto3
import io
client = boto3.client('kinesis',region_name="eu-west-3")

s3 = boto3.resource('s3')
s3_object = s3.Object('nvabucket', 'flights.csv')

csv_data = s3_object.get()['Body'].read().decode('utf-8')

df = pd.read_csv(io.StringIO(csv_data))

df

from pyspark.sql import SparkSession
import pyspark.sql.functions as sqlfunc
from pyspark.sql.types import *
import argparse, sys
from pyspark.sql import *
import pyspark.sql.functions as sqlfunc
import pandas as pd

def create_session(appname):
    spark_session = SparkSession\
        .builder\
        .appName(appname)\
        .master('yarn')\
        .config("hive.metastore.uris", "thrift://uds-far-mn1.dab.02.net:9083")\
        .enableHiveSupport()\
        .getOrCreate()
    return spark_session
### START MAIN ###
if __name__ == '__main__':
    spark_session = create_session('testing_files')

from pyspark.sql import SparkSession
# Pandas to Spark
csv = spark_session.createDataFrame(df)

csv.show(10)

# Select the columns we want to use
# data = csv.select("DayofMonth", "DayOfWeek", "Carrier", "OriginAirportID", "DestAirportID", "DepDelay", ((col("ArrDelay") > 15).cast("Int").alias("label")))
data = (csv
        .withColumn("DayofMonth", col("DayofMonth").cast(DoubleType()))
        .withColumn("DayOfWeek", col("DayOfWeek").cast(DoubleType()))
        .withColumn("OriginAirportID", col("OriginAirportID").cast(IntegerType()))
        .withColumn("DestAirportID", col("DestAirportID").cast(IntegerType()))
        .withColumn("DepDelay", col("DepDelay").cast("float"))
        .select("DayofMonth", "DayOfWeek", "Carrier", "OriginAirportID", "DestAirportID", "DepDelay", ((col("ArrDelay") > 15).cast("Int").alias("label"))))

print("Select the columns we want to use")

# Split the data into train and test
[train, test] = data.randomSplit([0.7, 0.3])
test = test.withColumnRenamed("label", "trueLabel")

print("Split the data into train and test")

# Create the pipeline
strIdx = StringIndexer(inputCol = "Carrier", outputCol = "CarrierIdx")
catVec = VectorAssembler(inputCols = ["CarrierIdx", "DayofMonth", "DayOfWeek", "OriginAirportID", "DestAirportID"], outputCol="catFeatures")
catIdx = VectorIndexer(inputCol = catVec.getOutputCol(), outputCol = "idxCatFeatures")
numVec = VectorAssembler(inputCols = ["DepDelay"], outputCol="numFeatures")
minMax = MinMaxScaler(inputCol = numVec.getOutputCol(), outputCol="normFeatures")
featVec = VectorAssembler(inputCols=["idxCatFeatures", "normFeatures"], outputCol="features")
lr = LogisticRegression(labelCol="label",featuresCol="features",maxIter=10,regParam=0.3)

#dt = DecisionTreeClassifier(labelCol="label", featuresCol="features")
pipeline = Pipeline(stages=[strIdx, catVec, catIdx, numVec, minMax, featVec, lr])

print("Create the pipeline")

# Train the model
pipelineModel = pipeline.fit(train)

print("Train the model")

# Make predictions
prediction = pipelineModel.transform(test)

print("Make predictions")

# Evaluate the model
evaluator = BinaryClassificationEvaluator(labelCol="trueLabel", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
aur = evaluator.evaluate(prediction)
print ("AUR = ", aur)

# Tune the model
paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.1]).addGrid(lr.maxIter, [10, 5]).addGrid(lr.threshold, 
                                                                                            [0.4, 0.3]).build()
cv = CrossValidator(estimator=pipeline, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, 
                    numFolds=2)

model = cv.fit(train)

# Make predictions
newPrediction = model.transform(test)

# Evaluate the model
evaluator2 = BinaryClassificationEvaluator(labelCol="trueLabel", rawPredictionCol="prediction", metricName="areaUnderROC")
aur2 = evaluator2.evaluate(newPrediction)
print( "AUR2 = ", aur2)